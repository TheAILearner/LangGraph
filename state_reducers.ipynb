{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a00156",
   "metadata": {},
   "source": [
    "### Reducers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5527d",
   "metadata": {},
   "source": [
    "- **Reducers** are key to understanding how updates from nodes are applied to the **State**.  \n",
    "- Each **key in the State** has its own independent **reducer function**.  \n",
    "- If no reducer function is explicitly specified, the default behavior is that all updates to that key **override** its previous value.  \n",
    "- There are a few different types of reducers:\n",
    "  1. **Pre-defined reducer functions**\n",
    "  2. **Custom reducer functions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483d7e8",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"langgraph_reducer_final.gif\" width=\"800\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d1a62",
   "metadata": {},
   "source": [
    "#### Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypedState(TypedDict):\n",
    "    name : str\n",
    "    topics : list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_a(state):\n",
    "    print(\"Node A received state:\", state)\n",
    "    return {\"name\" : state['name'] + 'Learner', \"topics\" : [\"langgraph\"]}\n",
    "\n",
    "def node_b(state):\n",
    "    print(\"Node B received state:\", state)\n",
    "    return {\"topics\" : ['langchain']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Image # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(TypedState)\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_edge(START, \"node_a\")\n",
    "builder.add_edge(\"node_a\", \"node_b\")\n",
    "builder.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"name\": \"AI\", \"topics\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4baee",
   "metadata": {},
   "source": [
    "Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(TypedState)\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_edge(START, \"node_a\")\n",
    "builder.add_edge(START, \"node_b\")\n",
    "builder.add_edge(\"node_a\", END)\n",
    "builder.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"name\": \"AI\", \"topics\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6afb3",
   "metadata": {},
   "source": [
    "#### Pre-defined Reducer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5dfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f119603",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReducerState(TypedDict):\n",
    "    name : str\n",
    "    topics : Annotated[list[str], add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a51577",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(ReducerState)\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_edge(START, \"node_a\")\n",
    "builder.add_edge(START, \"node_b\")\n",
    "builder.add_edge(\"node_a\", END)\n",
    "builder.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "graph.invoke({\"name\": \"AI\", \"topics\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b408f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"name\": \"AI\", \"topics\": None}) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ab154",
   "metadata": {},
   "source": [
    "#### Custom reducer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_reducer(left, right):\n",
    "    if not left:\n",
    "        return right\n",
    "    if not right:\n",
    "        return left\n",
    "    return left + right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReducerState(TypedDict):\n",
    "    name : str\n",
    "    topics : Annotated[list[str], custom_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(ReducerState)\n",
    "builder.add_node(\"node_a\", node_a)\n",
    "builder.add_node(\"node_b\", node_b)\n",
    "builder.add_edge(START, \"node_a\")\n",
    "builder.add_edge(START, \"node_b\")\n",
    "builder.add_edge(\"node_a\", END)\n",
    "builder.add_edge(\"node_b\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "graph.invoke({\"name\": \"AI\", \"topics\": None}) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb343bb",
   "metadata": {},
   "source": [
    "#### Chat Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c1cd2",
   "metadata": {},
   "source": [
    "\n",
    "- Most modern **LLM providers** support a **chat model interface** that accepts a list of messages as input.  \n",
    "- In **LangChain**, the `ChatModel` takes a list of **Message** objects such as:\n",
    "  - `HumanMessage` → user input  \n",
    "  - `AIMessage` → model response  \n",
    "- These message objects enable structured, multi-turn interactions between users and the model.  \n",
    "\n",
    "---\n",
    "\n",
    "##### Using Messages in Your Graph\n",
    "- Prior conversation history can be stored as a **list of messages** in your **graph state**.  \n",
    "- To do this, add a **key (channel)** to the state that holds a list of `Message` objects.  \n",
    "- Annotate this key with a **reducer function** to control how messages are updated.  \n",
    "- If no reducer is specified, **new updates overwrite** the previous list of messages.  \n",
    "- To **append** messages (i.e., keep the conversation history), use: reducer=add_messages from langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a461349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f106044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c63e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_msg = [HumanMessage(content=\"Hi\")]\n",
    "add_messages(inp_msg, AIMessage(content=\"Hello! How can I assist you today?\")) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4683f",
   "metadata": {},
   "source": [
    "Overwriting and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_msg = [HumanMessage(content=\"Hi\", name=\"user\", id=\"1\"),\n",
    "           AIMessage(content=\"Hello\", name=\"assistant\", id=\"2\")]\n",
    "add_messages(inp_msg, AIMessage(content=\"Hello! How can I assist you today?\", name=\"assistant\", id=\"2\")) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56166501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_msg = [HumanMessage(content=\"Hi\", name=\"user\", id=\"1\"),\n",
    "           AIMessage(content=\"Hello\", name=\"assistant\", id=\"2\"),\n",
    "           HumanMessage(content=\"Who will win fifa world cup 2026?\", name=\"user\", id=\"3\"),\n",
    "           AIMessage(content=\"I don't know yet as this is a future event.\", name=\"assistant\", id=\"4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84455cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_msgs = [RemoveMessage(m.id) for m in inp_msg if m.id in [\"1\", \"2\"]]\n",
    "deleted_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96412957",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_messages(inp_msg, deleted_msgs) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a33c2",
   "metadata": {},
   "source": [
    "#### MessageState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b24952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state):\n",
    "    return {\"messages\" : [AIMessage(content=\"Hello! How can I assist you today?\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fdd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": [HumanMessage(content=\"Hi!\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901bf19a",
   "metadata": {},
   "source": [
    "#### Real-life examples utilizing reducer functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3579b",
   "metadata": {},
   "source": [
    "##### 1. Metasearch Result Merger\n",
    "- Combines results from multiple search engines or data sources.  \n",
    "- The reducer merges, deduplicates, and ranks search results by relevance or confidence score.\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Map-Reduce Summarization\n",
    "- Each node summarizes a different chunk or section of a document.  \n",
    "- The reducer combines these partial summaries into a single cohesive summary.\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. Ensembling Model Outputs\n",
    "- Run Multiple LLM/prompts in parallel\n",
    "- Several LLM nodes produce alternative answers to the same query.  \n",
    "- The reducer compares outputs, scores them, and keeps the best or consensus response.\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. Multi-Vendor Price Aggregation\n",
    "- Used when multiple vendor APIs return prices for the same product.  \n",
    "- The reducer merges or averages the results to produce a unified price list or select the lowest price.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32434f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397b990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
